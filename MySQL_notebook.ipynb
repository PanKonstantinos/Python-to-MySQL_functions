{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7516bbd4-0fa5-4401-98a0-ad2dc81efdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import GEOparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f98ff-25a9-4074-906d-c982a96b0e73",
   "metadata": {},
   "source": [
    "#### Local version (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee4dc04-40ca-4e6f-b0bf-bffe8982c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    connection = pymysql.connect(host='localhost',\n",
    "                                 user='root',\n",
    "                                 #password='12345',\n",
    "                                 db='parent')\n",
    "    cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b513ffa-cbbe-42c1-b548-40eb9280e8fe",
   "metadata": {},
   "source": [
    "#### InSyBio server version (application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5580d0f0-a91d-4f8f-9664-46f818d72e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='server.com',\n",
    "                             user='user_name',\n",
    "                             password='213454',\n",
    "                             db='db_name')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6457767-71ca-4a34-8b5c-eb3dd627a8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('information_schema',),\n",
       " ('parent',),\n",
       " ('parent_etaireia',),\n",
       " ('parent_univdb',),\n",
       " ('performance_schema',))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SHOW DATABASES\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb9e9090-29e5-4a51-805f-b9b5b655de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available databases are:\n",
      "['information_schema', 'parent', 'parent_etaireia', 'parent_univdb', 'performance_schema']\n",
      "\n",
      "The available tables are:\n",
      "['dataset_to_differentialexpression', 'dataset_to_phenotypes', 'dataset_to_tissues', 'datasets', 'differential_expression', 'gene_to_transcript', 'genes', 'medication', 'phenotypes', 'preprocessed_data', 'processed_data', 'raw_dataset', 'sample_to_medication', 'sample_to_treatment', 'samples', 'tissues', 'transcript_expression', 'transcripts', 'treatment']\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SHOW DATABASES\") # Show the available databases in the host\n",
    "print(\"The available databases are:\")\n",
    "DB_names = []\n",
    "for x in cursor:\n",
    "    #print(*x)\n",
    "    DB_names.append(*x)\n",
    "print(DB_names,end=\"\\n\\n\")\n",
    "\n",
    "cursor.execute(\"SHOW TABLES\") # Show the tables of a specific database\n",
    "print(\"The available tables are:\")\n",
    "table_names = []\n",
    "for x in cursor:\n",
    "    #print(x)\n",
    "    table_names.append(*x)\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5998b-16f5-4291-8699-542ab3a78e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5a748b-ff1f-4948-9fc8-b5466e2a2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tables in the parent DataBase are:\n",
      "\n",
      "dataset_to_differentialexpression\n",
      "dataset_to_phenotypes\n",
      "dataset_to_tissues\n",
      "datasets\n",
      "differential_expression\n",
      "gene_to_transcript\n",
      "genes\n",
      "medication\n",
      "phenotypes\n",
      "preprocessed_data\n",
      "processed_data\n",
      "raw_dataset\n",
      "sample_to_medication\n",
      "sample_to_treatment\n",
      "samples\n",
      "tissues\n",
      "transcript_expression\n",
      "transcripts\n",
      "treatment\n"
     ]
    }
   ],
   "source": [
    "if connection.db:\n",
    "    #print(str(connection.db).split(\"\\'\")[1])\n",
    "    db = str(connection.db).split(\"\\'\")[1]\n",
    "\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "print(f'The tables in the {db} DataBase are:\\n')\n",
    "for i in cursor.fetchall():\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07c5aa-0410-4481-9c8a-322594d6b3b8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11628dd0-c164-4038-82ea-7bd6202aab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(engine, cursor, table, columns, values, verbose = False):\n",
    "    ''' Adds an instance in a table as a row.\n",
    "    Inputs: \n",
    "    <object> engine. The connection to the database\n",
    "    <Object> curasor. The entity that \\'talks\\' to the database\n",
    "    <str> table. The table's name we need to add the instance\n",
    "    <list-like> values. The values we need to add to the table of the database\n",
    "    '''\n",
    "    columns = tuple(columns)\n",
    "    # if str(type(df)).startswith(\"<class \\'pandas.core\"):\n",
    "    #     values = list(values.itertuples(index=False))\n",
    "    print(f'This is the original: {values}')\n",
    "    values = tuple(values)\n",
    "    positions = len(columns)\n",
    "    sql = f\"INSERT INTO {table} ({','.join([str(s) for s in list(columns)])}) VALUES ({str('%s, '*len(columns)).strip().strip(',')})\" #SQL command structure\n",
    "    if verbose:\n",
    "        print(values)\n",
    "        print(type(values))\n",
    "    cursor.executemany(sql, [values]) # Execute multiple lines\n",
    "    engine.commit() # Commit the change to happen\n",
    "\n",
    "    print(cursor.rowcount, \"record inserted.\")\n",
    "    print(f'Last ID: {cursor.lastrowid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58012e64-2c6f-4ca1-9afe-36b8ae4df4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_ID(table):\n",
    "    '''Restores the Ids of a table in the database\n",
    "    Input: <str> table. The table's name we need to restore the ID'''\n",
    "    try:\n",
    "        sql = f\"ALTER TABLE {table} AUTO_INCREMENT = 1\" #SQL command structure\n",
    "        cursor.execute(sql)\n",
    "        connection.commit()\n",
    "        print('Prmary Key restored!')\n",
    "    except:\n",
    "        print('Prmary Key restoration failed!')\n",
    "        print('call the \\'restore_ID(table_name)\\' again with the correct name!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18d1117-03da-4cbe-807c-f86bf8c51d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_table(table):\n",
    "    if str(input(f'This will delete all instances of the {table} table.\\nContinue? [Y/N]: ')).lower() in ['y','yes']:\n",
    "        try:\n",
    "            sql = f\"DELETE FROM {table}\" #SQL command structure\n",
    "            cursor.execute(sql)\n",
    "            connection.commit()\n",
    "            print(f'All instances of the {table} table deleted. The table is now empty.')\n",
    "            if str(input(f'Restore the Primary Key ID? [Y/N]: ')).lower() in ['y','yes']:\n",
    "                restore_ID(table)\n",
    "        except:\n",
    "            print(f'Check the name of the table. It seems that {table} is no in the database.')\n",
    "    else:\n",
    "        print(f'Action aborted. No cange made in {table} table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83365465-b1a7-4cc8-8f8e-6fbc1e9eb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_engine(host='localhost', user='root', passord='', db='parent'):\n",
    "    engine = create_engine(f\"mysql+pymysql://{user}:{passord}@{host}/{db}\")\n",
    "    print(f\"mysql+pymysql://{user}:{passord}@{host}/{db}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec730c32-d578-4aca-a58c-0f0f0cca8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(table, columns):\n",
    "    columns = tuple(columns)\n",
    "    table = 'datasets'\n",
    "    flat_str = ', '.join([f\"DROP COLUMN {i}\" for i in columns])\n",
    "    sql_query = f'ALTER TABLE datasets {flat_str}'\n",
    "    cursor.execute(sql_query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57c49e8-dae6-4ef4-b6d0-9193f61ee9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_PrimaryKey(table, key):\n",
    "    sql = f\"ALTER TABLE {table} DROP INDEX {key}; \"\n",
    "    cursor.execute(sql)\n",
    "    connection.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005ede72-b897-4316-95ae-eb60e38b9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_subset_data(index, dataframe):\n",
    "    print(dataframe.iloc[index,],sep='\\n\\n')\n",
    "    return dataframe.iloc[index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd071143-2b08-43e9-8879-be0aa9ead6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_subset_data(table, dataframe):\n",
    "    #dataframe_tmp = dataframe.copy()\n",
    "    #dataframe_tmp.set_index(dataframe_tmp.columns.values[0], inplace=True)\n",
    "    table = str(table).lower()\n",
    "    if table=='datasets':\n",
    "        index = ['GEO_ID', 'Dataset_url', 'Platform_ID', 'Platform_name', 'Expererimental_protocol']\n",
    "    \n",
    "    elif table=='raw_dataset':\n",
    "        index = ['Raw_path']\n",
    "    \n",
    "    elif table=='preprocessed_data':\n",
    "        index = ['Preprocessed_url', 'Preprocessed_download', 'Preprocessing_description']\n",
    "    \n",
    "    elif table=='processed_data':\n",
    "        index = ['Processed_path', 'Processed_path_integration']\n",
    "    \n",
    "    elif table=='differential_expression':\n",
    "        index = ['Source_file_path', 'Volcano_file_path', 'boxplot_file_path', 'heatmap_file_path']\n",
    "    \n",
    "    elif table=='phenotypes':\n",
    "        index = ['Phenotype_name']\n",
    "    \n",
    "    elif table=='tissues':\n",
    "        index = ['tissue_name']\n",
    "    \n",
    "    #index = list(filter(lambda x: dataframe.index[x] in index, range(len(dataframe))))\n",
    "    print(dataframe.loc[index,],sep='\\n\\n')\n",
    "    return dataframe.loc[index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d6d1ed-7647-432b-b922-f4dd8714f668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_auto_ID(table):\n",
    "    cursor.execute(f'SELECT `AUTO_INCREMENT` FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = %s',args=table)\n",
    "    current_ID = cursor.fetchone()[0] - 1\n",
    "    next_ID = current_ID + 1\n",
    "    print(f'Current ID = {current_ID}\\nNext ID = {next_ID}')\n",
    "    return current_ID, next_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a1c59-98c4-4e4d-9e81-89602f31fa46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890ca01a-3279-4fe3-a79c-4131c4763d2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide the GEO accession number for the Series\n",
      "Leave empty for the example dataset GSE6575:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Jul-2023 11:50:45 DEBUG utils - Directory ./ already exists. Skipping.\n",
      "31-Jul-2023 11:50:45 INFO GEOparse - File already exist: using local version.\n",
      "31-Jul-2023 11:50:45 INFO GEOparse - Parsing ./GSE6575_family.soft.gz: \n",
      "31-Jul-2023 11:50:45 DEBUG GEOparse - DATABASE: GeoMiame\n",
      "31-Jul-2023 11:50:45 DEBUG GEOparse - SERIES: GSE6575\n",
      "31-Jul-2023 11:50:45 DEBUG GEOparse - PLATFORM: GPL570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating the parshing of data from GEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\GEOparse\\GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "31-Jul-2023 11:50:46 DEBUG GEOparse - SAMPLE: GSM151962\n",
      "31-Jul-2023 11:50:46 DEBUG GEOparse - SAMPLE: GSM151963\n",
      "31-Jul-2023 11:50:46 DEBUG GEOparse - SAMPLE: GSM151964\n",
      "31-Jul-2023 11:50:46 DEBUG GEOparse - SAMPLE: GSM151965\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151966\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151967\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151968\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151969\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151970\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151971\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151972\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151973\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151974\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151975\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151976\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151977\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151978\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151979\n",
      "31-Jul-2023 11:50:47 DEBUG GEOparse - SAMPLE: GSM151980\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151981\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151982\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151983\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151984\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151985\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151986\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151987\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151988\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151989\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151990\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151991\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151992\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151993\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151994\n",
      "31-Jul-2023 11:50:48 DEBUG GEOparse - SAMPLE: GSM151995\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM151996\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM151997\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM151998\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM151999\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152000\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152001\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152002\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152003\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152004\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152005\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152006\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152007\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152008\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152009\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152010\n",
      "31-Jul-2023 11:50:49 DEBUG GEOparse - SAMPLE: GSM152011\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152012\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152013\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152014\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152015\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152016\n",
      "31-Jul-2023 11:50:50 DEBUG GEOparse - SAMPLE: GSM152017\n"
     ]
    }
   ],
   "source": [
    "# GSE6575\n",
    "gse = input('Provide the GEO accession number for the Series\\nLeave empty for the example dataset GSE6575: ')\n",
    "if len(gse)==0:\n",
    "    gse = 'GSE6575'\n",
    "data = {}\n",
    "if gse.startswith('GSE'):\n",
    "    print('Initiating the parshing of data from GEO')\n",
    "    data[gse] = GEOparse.get_GEO(geo=gse)#, silent=True)\n",
    "else:\n",
    "    print(f'{gse} seems not to be a GEO Series, because it doesn\\'t start with \\'GSE...\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "239dd7f5-5c43-4dea-b16f-22b59b081af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,),)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(f'SELECT `AUTO_INCREMENT` FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = %s',args=table)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "eddd6b84-b2fc-4403-a834-33ab55543e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "afe40dc5-bd5b-4ee1-b739-e3d48aa95493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441083ec-e0b3-4c58-9bfb-cf810f9dc093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98772b2-820a-4e63-ac49-11cb7e251397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list(data.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c36806-f8eb-4825-a596-6ca164beb8a1",
   "metadata": {},
   "source": [
    "# Read Excel data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eaecd073-c84a-482d-b94d-48bf40a26132",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07-Projects\\Bioinformatics_WG\\Bioinfo_WG\n",
      "GSE111175\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\UTENTE\\\\Desktop\\\\PoliTo\\\\PARENT\\\\07-Projects\\\\Bioinformatics_WG\\\\Bioinfo_WG\\\\GSE111175\\\\GSE111175_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dest \u001b[38;5;129;01min\u001b[39;00m b:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dest)\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdest\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_info.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py:266\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    267\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    268\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    269\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\UTENTE\\\\Desktop\\\\PoliTo\\\\PARENT\\\\07-Projects\\\\Bioinformatics_WG\\\\Bioinfo_WG\\\\GSE111175\\\\GSE111175_info.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "#filename = os.path.join(dirname, 'relative/path/to/file/you/want')\n",
    "starting_path =  os.getcwd()\n",
    "print(os.getcwd())\n",
    "files = glob.glob('*.csv')\n",
    "\n",
    "files\n",
    "\n",
    "if False:\n",
    "    os.chdir(\"./Bioinfo_WG/\")\n",
    "    print(os.getcwd())\n",
    "\n",
    "b = glob.glob('GSE*')\n",
    "b = [f for f in b if not '.' in f]\n",
    "\n",
    "\n",
    "for dest in b:\n",
    "    print(dest)\n",
    "    shutil.copyfile(files[0], dst=os.path.join(os.getcwd(),dest,f'{dest}_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b026e80-7f79-4e43-bf09-3e339f98cf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE111175\n"
     ]
    }
   ],
   "source": [
    "gse = b[0]\n",
    "print(gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b763d-11c0-44da-8993-3d8fd01bfb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bfd240-a033-438a-8265-205b70080d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9297fdb3-1b8f-48a2-95c5-bc569c7e8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(f'C:/Users/UTENTE/Desktop/PoliTo/PARENT/07-Projects/Bioinformatics_WG/Bioinfo_WG/{gse}/{gse}_info.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e77197c5-f59f-4d92-9463-2e9376dcd2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Datasets_ID</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO_ID</th>\n",
       "      <td>GSE6575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_url</th>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform_ID</th>\n",
       "      <td>GPL570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform_name</th>\n",
       "      <td>[HG-U133_Plus_2] Affymetrix Human Genome U133 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expererimental_protocol</th>\n",
       "      <td>Gene expression in blood of children with auti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raw_path</th>\n",
       "      <td>C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preprocessed_url</th>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preprocessed_download</th>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/geo/download/?acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preprocessing_description</th>\n",
       "      <td>Normalized intensity value calculated from Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Processed_path</th>\n",
       "      <td>C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Processed_path_integration</th>\n",
       "      <td>C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source_file_path</th>\n",
       "      <td>C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volcano_file_path</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boxplot_file_path</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heatmap_file_path</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phenotype_name</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tissue_name</th>\n",
       "      <td>Whole blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            1\n",
       "0                                                                            \n",
       "Datasets_ID                                                               NaN\n",
       "GEO_ID                                                                GSE6575\n",
       "Dataset_url                 https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi...\n",
       "Platform_ID                                                            GPL570\n",
       "Platform_name               [HG-U133_Plus_2] Affymetrix Human Genome U133 ...\n",
       "Expererimental_protocol     Gene expression in blood of children with auti...\n",
       "Raw_path                    C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...\n",
       "Preprocessed_url            https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi...\n",
       "Preprocessed_download       https://www.ncbi.nlm.nih.gov/geo/download/?acc...\n",
       "Preprocessing_description   Normalized intensity value calculated from Pro...\n",
       "Processed_path              C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...\n",
       "Processed_path_integration  C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...\n",
       "Source_file_path            C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...\n",
       "Volcano_file_path                                                         NaN\n",
       "boxplot_file_path                                                         NaN\n",
       "heatmap_file_path                                                         NaN\n",
       "Phenotype_name                                                            NaN\n",
       "tissue_name                                                       Whole blood"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "85fc0083-ce96-498a-ae51-b927980256a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This GEO ID (GSE6575) has been found in the database.\n",
      "((1,), (2,))\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(f'SELECT GEO_ID FROM datasets')\n",
    "ids = cursor.fetchall()\n",
    "geo_ID = data_file.loc['GEO_ID'].values[0]\n",
    "if geo_ID in [ls[0] for ls in ids]:\n",
    "    print(f'This GEO ID ({geo_ID}) has been found in the database.')\n",
    "    cursor.execute('SELECT Dataset_ID FROM datasets WHERE GEO_ID = %s', geo_ID)\n",
    "    print(cursor.fetchall())\n",
    "else:\n",
    "    print(f'Starting the insertion of the dataset with GEO ID: {geo_ID}.')\n",
    "    cursor.execute('SELECT Dataset_ID FROM datasets WHERE GEO_ID = %s', geo_ID)\n",
    "    cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c9788776-6b0c-4c08-85da-c8aa40344537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GSE6575'], dtype=object)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "bd706e74-62e6-4ac1-9260-eadb12b1f9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM datasets WHERE GEO_ID = %s', [geo_ID[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3c6695b1-9f49-4d81-9bf2-6a0d40c77e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'GSE6575',\n",
       " 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE6575',\n",
       " 'GPL570',\n",
       " '[HG-U133_Plus_2] Affymetrix Human Genome U133 Plus 2.0 Array',\n",
       " 'Gene expression in blood of children with autism spectrum disorder (ASD) was studied. Transcriptional profiles were compared with age and gender matched, typically developing children from the general population (GP) or IQ matched children with mental retardation or developmental delay (MR/DD).')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM datasets WHERE Dataset_ID = %s', [2])\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a3a2f89b-b78a-471e-b9a5-7e0ba82a5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current ID = 2\n",
      "Next ID = 3\n"
     ]
    }
   ],
   "source": [
    "current_id, upcomming_id = get_auto_ID('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7adcff75-9a71-477a-8c51-7713cd2ea2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT LAST_INSERT_ID()')\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "41e61966-48ff-4d16-8a31-e8baf97cbdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         1\n",
      "0                                                                         \n",
      "GEO_ID                                                             GSE6575\n",
      "Dataset_url              https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi...\n",
      "Platform_ID                                                         GPL570\n",
      "Platform_name            [HG-U133_Plus_2] Affymetrix Human Genome U133 ...\n",
      "Expererimental_protocol  Gene expression in blood of children with auti...\n",
      "This is the original: ['GSE6575' 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE6575'\n",
      " 'GPL570' '[HG-U133_Plus_2] Affymetrix Human Genome U133 Plus 2.0 Array'\n",
      " 'Gene expression in blood of children with autism spectrum disorder (ASD) was studied. Transcriptional profiles were compared with age and gender matched, typically developing children from the general population (GP) or IQ matched children with mental retardation or developmental delay (MR/DD).']\n",
      "('GSE6575', 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE6575', 'GPL570', '[HG-U133_Plus_2] Affymetrix Human Genome U133 Plus 2.0 Array', 'Gene expression in blood of children with autism spectrum disorder (ASD) was studied. Transcriptional profiles were compared with age and gender matched, typically developing children from the general population (GP) or IQ matched children with mental retardation or developmental delay (MR/DD).')\n",
      "<class 'tuple'>\n",
      "1 record inserted.\n",
      "Last ID: 2\n",
      "                                                          1\n",
      "0                                                          \n",
      "Raw_path  C:\\Users\\UTENTE\\Desktop\\PoliTo\\PARENT\\07 - Pro...\n",
      "This is the original: ['C:\\\\Users\\\\UTENTE\\\\Desktop\\\\PoliTo\\\\PARENT\\\\07 - Projects\\\\Bioinformatics_WG\\\\Bioinfo_WG\\\\GSE6575\\\\GSE6575_RAW.tar']\n",
      "('C:\\\\Users\\\\UTENTE\\\\Desktop\\\\PoliTo\\\\PARENT\\\\07 - Projects\\\\Bioinformatics_WG\\\\Bioinfo_WG\\\\GSE6575\\\\GSE6575_RAW.tar',)\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(1452, 'Cannot add or update a child row: a foreign key constraint fails (`parent`.`raw_dataset`, CONSTRAINT `raw_to_dataset_fk` FOREIGN KEY (`Datasets_ID`) REFERENCES `datasets` (`Dataset_ID`) ON DELETE NO ACTION ON UPDATE NO ACTION)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[221], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m RawData_table \u001b[38;5;241m=\u001b[39m table_subset_data(table_name, data_file)\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m RawData_table\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 18\u001b[0m \u001b[43madd_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m PreprocessedData_table \u001b[38;5;241m=\u001b[39m table_subset_data(table_name, data_file)\n",
      "Cell \u001b[1;32mIn[185], line 12\u001b[0m, in \u001b[0;36madd_row\u001b[1;34m(engine, cursor, table, columns, values)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(values)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(values))\n\u001b[1;32m---> 12\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Execute multiple lines \u001b[39;00m\n\u001b[0;32m     13\u001b[0m engine\u001b[38;5;241m.\u001b[39mcommit() \u001b[38;5;66;03m# Commit the change to happen\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(cursor\u001b[38;5;241m.\u001b[39mrowcount, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord inserted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:182\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    180\u001b[0m     q_postfix \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_execute_many\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_postfix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_stmt_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:220\u001b[0m, in \u001b[0;36mCursor._do_execute_many\u001b[1;34m(self, prefix, values, postfix, args, max_stmt_length, encoding)\u001b[0m\n\u001b[0;32m    218\u001b[0m         sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 220\u001b[0m rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpostfix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m rows\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rows\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1203\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m     \u001b[43mpacket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 221\u001b[0m \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`parent`.`raw_dataset`, CONSTRAINT `raw_to_dataset_fk` FOREIGN KEY (`Datasets_ID`) REFERENCES `datasets` (`Dataset_ID`) ON DELETE NO ACTION ON UPDATE NO ACTION)')"
     ]
    }
   ],
   "source": [
    "# dataset_table = index_subset_data(range(0,4), data_file)\n",
    "# RawData_table = index_subset_data(range(4,5), data_file)\n",
    "# PreprocessedData_table = index_subset_data(range(5,8), data_file)\n",
    "# processedData_table = index_subset_data(range(8,10), data_file)\n",
    "# processedData_table = index_subset_data(range(10,11), data_file)\n",
    "# DiffExp_table = index_subset_data(range(10,14), data_file)\n",
    "# Pheno_table = index_subset_data(range(14,15), data_file)\n",
    "# Tissue_table = index_subset_data(range(15,16), data_file)\n",
    "\n",
    "table_name = 'Datasets'\n",
    "dataset_table = table_subset_data(table_name, data_file)\n",
    "df = dataset_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'raw_dataset'\n",
    "RawData_table = table_subset_data(table_name, data_file)\n",
    "df = RawData_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'preprocessed_data'\n",
    "PreprocessedData_table = table_subset_data(table_name, data_file)\n",
    "df = PreprocessedData_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'processed_data'\n",
    "processedData_table = table_subset_data(table_name, data_file)\n",
    "df = processedData_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'differential_expression'\n",
    "DiffExp_table = table_subset_data(table_name, data_file)\n",
    "df = DiffExp_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'phenotypes'\n",
    "Pheno_table = table_subset_data(table_name, data_file)\n",
    "df = Pheno_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n",
    "\n",
    "table_name = 'tissues'\n",
    "Tissue_table = table_subset_data(table_name, data_file)\n",
    "df = Tissue_table.copy()\n",
    "add_row(connection, cursor, table_name, df.index.values, df.values[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b1b00-63fe-4236-b0eb-7c339c65cc1b",
   "metadata": {},
   "source": [
    "# Insertion of data to the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780af41-21e3-43a9-861a-cefb4e6ab400",
   "metadata": {},
   "source": [
    "## Get information for all Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ec800-cb41-4d51-b2d3-e56f514f9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.phenotype_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cceb7-2a50-4516-9fea-0410826105c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.phenotype_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb49aea-de3d-4ea5-880c-0bf1725390ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40707246-be18-4da9-a228-e659c39422c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d42fc9-cdc1-487a-91e5-2641bf96166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gsms[list(data.gsms.keys())[0]].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923d550-4f98-4594-ba85-a56667053e1b",
   "metadata": {},
   "source": [
    "## Get the Data of 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5d0b5-0beb-4c5a-9776-74776f0bab52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.gsms[list(data.gsms)[0]].table # Transcript_expression table linked to the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53077ba-aa60-4ac3-b061-e5f11a435093",
   "metadata": {},
   "source": [
    "## Get GPL (Platform) info. Like f <- fData(gse) in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d2eff-ee1e-48ff-9294-4c1ecba83a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(list(data.gpls))>1: \n",
    "    print('There are {len(list(data.gpls))} GPLs')\n",
    "data.gpls[list(data.gpls)[0]].table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1a70d-ca32-4e9f-84b4-0046d6ed35b8",
   "metadata": {},
   "source": [
    "### Get information about the GPL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7749e-9579-43b6-a769-3f79ae0395cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls.keys())[0]].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48828cdf-a909-4788-8008-2f5a62dd3722",
   "metadata": {},
   "source": [
    "### Create Variables starting with _DB_ with the names of all the tables of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f2957-cf6f-43d5-998c-9795b451a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {}\n",
    "for nome in table_names:\n",
    "    cursor.execute(f'SHOW COLUMNS FROM {nome}')\n",
    "    column_names[nome] = []\n",
    "    for x in cursor:\n",
    "        #print(x)\n",
    "        column_names[nome].append(list(x)[0])\n",
    "    #print('\\n',column_names)\n",
    "    #globals()[f\"_DB_{nome}\"] = pd.DataFrame(column_names)\n",
    "Database = pd.Series(column_names[list(column_names.keys())[0]], name=list(column_names.keys())[0])\n",
    "for i in range(1,len(column_names.keys())):\n",
    "    Database = pd.concat([Database, pd.Series(column_names[list(column_names.keys())[i]], name=list(column_names.keys())[i])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeea92c-00a0-462e-9b47-732ebb46c8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a942e70-ebb9-4b88-a3d0-f2731e9208a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649404c-3304-44a0-bf9c-c1d5a6652e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute('ALTER TABLE `datasets` ADD `Description` TEXT CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL ; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6796588-8e02-4c37-8b03-94b622629ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SHOW COLUMNS FROM datasets')\n",
    "\n",
    "column_names = []\n",
    "columns = []\n",
    "for x in cursor:\n",
    "    print(x)\n",
    "    columns.append(list(x))\n",
    "    column_names.append(list(x)[0])\n",
    "print('\\n',column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87df07-9b17-4634-9f20-11d0b125bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.setdiff1d(Database.datasets.values.flatten(), insert_data.columns))\n",
    "\n",
    "columns = pd.DataFrame(np.array(columns)[:,1:], index=np.array(columns)[:,0], columns=['Type','Null','Key_type','Default','Auto_fill_type'])\n",
    "\n",
    "columns.loc[np.setdiff1d(Database.datasets.values.flatten(), insert_data.columns),'Null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac6415-e15c-423d-b833-8fa1f8a98710",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in columns.index:\n",
    "    \n",
    "    if col_name in insert_data.columns:\n",
    "        #print(col_name, 'Value: ', insert_data[col_name].values[0])\n",
    "        columns.loc[col_name,'value'] = insert_data[col_name].values[0]\n",
    "    else: columns.loc[col_name,'value'] = ''\n",
    "    \n",
    "    #if columns.loc[col_name,'Null']=='NO' and columns.loc[col_name,'value'] == '': \n",
    "        #print(f'The column {col_name} needs to be filled')\n",
    "        #print('These columns will take a value of 9999')\n",
    "columns.loc[(columns['Null']=='NO') & (columns['Auto_fill_type']!='auto_increment') & (columns['value']==''), 'value'] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bcf45-81fc-4033-94d2-b64af62fe09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac642f-0700-4233-8c26-3af3888f56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'datasets'\n",
    "values = tuple(columns['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc695e39-f0c8-4ffd-b1ad-92b50f196eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns.T.iloc[-1,:].to_sql(table, con=connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdef3eb-042c-4a79-847a-2b36d4604169",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SHOW ENGINE INNODB STATUS')\n",
    "query = 'LATEST FOREIGN KEY ERROR'\n",
    "for i in cursor:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38182813-ee28-4ac0-a03b-c67cf3976b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_ID(table='datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fd838-147e-40db-a7f6-f9a87ad3903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_row(connection, cursor,table, columns=tuple(columns.index.values), values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17fe76-a721-4526-921a-86d101d3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all_in_table('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598b87e-1be2-4743-b297-7cdc18e0b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    sql = \"ALTER TABLE datasets DROP INDEX foreign_key_12; \" #Else run the function drop_PrimaryKey(table,key)\n",
    "    cursor.execute(sql)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6013d3b-9d96-4497-a3d4-b24e6ace704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    drop_column('dataset',('Raw_ID','Processed_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abd27d-d130-476e-9968-96d5edba8322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59970370-7c88-4da4-8476-5f18d0f0f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patien_1 = GEOparse.(data.metadata['sample_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c9c3d-60c7-413f-bd78-e037e97c072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata['sample_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48a4a9-389e-4eaf-bb84-183104936e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl = GEOparse.GPL(data.metadata['platform_id'][0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "068ead7a-e9fd-4236-90cd-a7371cd4d341",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    " merge_and_average(platform, expression_column, group_by_column, force=False, merge_on_column=None, gsm_on=None, gpl_on=None)[source]\n",
    "\n",
    "    Merge and average GSE samples.\n",
    "\n",
    "    For given platform prepare the DataFrame with all the samples present in the GSE annotated with given column from platform and averaged over the column.\n",
    "    Parameters:\t\n",
    "\n",
    "        platform (str or GEOparse.GPL) – GPL platform to use.\n",
    "        expression_column (str) – Column name in which “expressions” are represented\n",
    "        group_by_column (str) – The data will be grouped and averaged over this column and only this column will be kept\n",
    "        force (bool) – If the name of the GPL does not match the platform name in GSM proceed anyway\n",
    "        merge_on_column (str) – Column to merge the data on - should be present in both GSM and GPL\n",
    "        gsm_on (str) – In the case columns to merge are different in GSM and GPL use this column in GSM\n",
    "        gpl_on (str) – In the case columns to merge are different in GSM and GPL use this column in GPL\n",
    "\n",
    "    Returns:\t\n",
    "\n",
    "    Merged and averaged table of results.\n",
    "    Return type:\t\n",
    "\n",
    "    pandas.DataFrame\n",
    "    \n",
    "###############################################################################################################################################################\n",
    " pivot_samples(values, index='ID_REF')[source]\n",
    "\n",
    "    Pivot samples by specified column.\n",
    "\n",
    "    Construct a table in which columns (names) are the samples, index is a specified column eg. ID_REF and values in the columns are of one specified type.\n",
    "    Parameters:\t\n",
    "\n",
    "        values (str) – Column name present in all GSMs.\n",
    "        index (str, optional) – Column name that will become an index in pivoted table. Defaults to “ID_REF”.\n",
    "\n",
    "    Returns:\t\n",
    "\n",
    "    Pivoted data\n",
    "    Return type:\t\n",
    "\n",
    "    pandas.DataFrame\n",
    "    \n",
    "###############################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee8702-5e9f-4a1c-8e05-bc0623760e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls)[0]].table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2dc39-1b5a-4f06-bdd0-971b150c2b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.gsms[list(data.gsms.keys())[5]].annotate(data.gpls[list(data.gpls)[0]].table, annotation_column='ENTREZ_GENE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822d538-54bf-4458-8719-3c858ccc08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls)[0]].table.loc[:,'ENTREZ_GENE_ID'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36dade-027e-43d7-be9c-26fca827cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls)[0]].table.loc[:,'GB_ACC'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeef98a-fb27-4432-811b-3ff79cd70624",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls)[0]].table.loc[:,'Gene Symbol'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7e9d6-90b5-47aa-834f-31b80ac18027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls)[0]].table.loc[:,'Representative Public ID'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65063aa2-3b1c-4c02-9761-ba09bcdbb4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552dfd1-df18-4f7d-989d-f03e68abd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOparse.GEOTypes.GSM(data.gsms, metadata, table, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeab03a-876f-4f4d-9042-e56cf24a14cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bd6c4-6eba-4b0f-a4d9-69b5540ec5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b904a3-b28c-45d2-9af5-64aefc708923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.gsms[list(data.gsms)[0]].table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e6516-9bd2-44a4-b7bd-a7e3e635b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Get expression data and metadata matrices\n",
    "exprs = []\n",
    "gsmNames = []\n",
    "metadata = {}\n",
    "for gsm_name, gsm in data.gsms.items():\n",
    "    if gsm.metadata['type'][0]=='RNA':\n",
    "        # Expression data\n",
    "        if len(gsm.table)>0:\n",
    "            tmp = gsm.table['VALUE']\n",
    "            tmp.index = gsm.table['ID_REF']\n",
    "            gsmNames.append(gsm_name)\n",
    "            if len(exprs)==0:\n",
    "                exprs = tmp.to_frame()\n",
    "            else:\n",
    "                exprs = pd.concat([exprs,tmp.to_frame()],axis=1)\n",
    "\n",
    "        # Metadata\n",
    "        for key,value in data.metadata.items():\n",
    "            #print(key)\n",
    "            #print(value)\n",
    "            if (key=='characteristics_ch1' or key=='characteristics_ch2') and (len([i for i in value if i!=''])>1 or value[0].find(': ')!=-1):\n",
    "                #print(value)\n",
    "                tmpVal = 0\n",
    "                for tmp in value:\n",
    "                    splitUp = [i.strip() for i in tmp.split(':')]\n",
    "                    #print(splitUp)\n",
    "                    if len(splitUp)==2:\n",
    "                        if not splitUp[0] in metadata:\n",
    "                            metadata[splitUp[0]] = {}\n",
    "                        metadata[splitUp[0]][gsm_name] = splitUp[1]\n",
    "                    else:\n",
    "                        if not key in metadata:\n",
    "                            metadata[key] = {}\n",
    "                        metadata[key][gsm_name] = splitUp[0]\n",
    "            else:\n",
    "                if not key in metadata:\n",
    "                    metadata[key] = {}\n",
    "                if len(value)==1:\n",
    "                    metadata[key][gsm_name] = ' '.join([j.replace(',',' ') for j in value])\n",
    "\n",
    "# Write expression data matrix to file\n",
    "exprs.columns = gsmNames\n",
    "#with open('exprs/'+gse1+'_exprs.csv','w') as outFile:\n",
    "#    exprs.to_csv(outFile)\n",
    "\n",
    "# Write metadata matrix to file\n",
    "#with open('pData/'+gse1+'_pData.csv','w') as outFile:\n",
    "#    outFile.write('Metadata,'+','.join(gsmNames))\n",
    "#    for key in metadata:\n",
    "#        tmp = [key]\n",
    "#        for gsm_name in gsmNames:\n",
    "#            if gsm_name in metadata[key]:\n",
    "#                tmp.append(metadata[key][gsm_name])\n",
    "#            else:\n",
    "#                tmp.append('NA')\n",
    "#        outFile.write('\\n'+','.join(tmp))\n",
    "\n",
    "# Plot boxplot of expression data\n",
    "plt.boxplot(exprs.transpose(),showfliers=False)\n",
    "plt.title(gse1)\n",
    "pdf.savefig()\n",
    "plt.close()\n",
    "try:\n",
    "    plt.boxplot(np.log2(exprs).transpose(),showfliers=False)\n",
    "    plt.title('log2('+gse1+')')\n",
    "    #pdf.savefig()\n",
    "    plt.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Write out platform information\n",
    "#for gpl_name, gpl in gse.gpls.items():\n",
    "#    with open('annot/'+gse1+'_'+gpl_name+'_gpl.csv','w') as outFile:\n",
    "#        gpl.table.to_csv(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0c637-c816-486a-83e9-2e57185bfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls.keys())[0]].table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8b3a8-87b1-4a53-9ed9-b0a0a54d6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gpls[list(data.gpls.keys())[0]].table.loc[not data.gpls[list(data.gpls.keys())[0]].table['REFSEQ'].isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487867eb-e734-465f-9c7e-b69a616ea8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa1d13-e0b7-43b3-b59b-5c2f43d67aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712928c-63ca-4ffc-8a9a-cf44421571fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4d6159-5c35-42cc-88f2-eb30ec9ea2aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fa265-ccae-475e-b4e8-dab1bc0c7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    sql = \"INSERT INTO raw_dataset (Raw_ID, Raw_path) VALUES (%s, %s)\" #SQL command structure\n",
    "    val = (\"\", f\"./missing_ID_{i}.txt\") # Values corresponding to the rows of an instance\n",
    "    cursor.execute(sql, val) # Execute the command\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58e22a-c2e1-4b73-987a-71a298f41603",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'raw_dataset'\n",
    "columns = tuple(['Raw_ID', 'Raw_path'])\n",
    "positions = len(columns)\n",
    "sql = f\"INSERT INTO {table} ({','.join([str(s) for s in list(columns)])}) VALUES ({str('%s, '*len(columns)).strip().strip(',')})\" #SQL command structure\n",
    "val = [(\"\", \"./missing_ID_2.txt\"),\n",
    "      (\"\", \"./missing_ID_3.txt\"),\n",
    "      (\"\", \"./missing_ID_4.txt\"),\n",
    "      (\"\", \"./missing_ID_5.txt\")]# Values corresponding to the rows of an instance\n",
    "cursor.executemany(sql, val) # Execute multiple lines \n",
    "\n",
    "connection.commit() # Commit the change to happen\n",
    "\n",
    "print(cursor.rowcount, \"record inserted.\")\n",
    "print(f'Last ID: {cursor.lastrowid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34876767-edbe-4061-a5eb-0595400131d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'preprocessed_data'\n",
    "sql = f\"DELETE FROM {table}\" #SQL command structure\n",
    "cursor.execute(sql)\n",
    "connection.commit()\n",
    "if str(input(f'Restore the Auto-increment ID of the table {table}? [Y/N]')).lower() in ['y','yes','ye']:\n",
    "    sql = f\"ALTER TABLE {table} AUTO_INCREMENT = 1\" #SQL command structure\n",
    "    cursor.execute(sql)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fabdaf-f11c-4866-bc89-833e20b2a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'raw_dataset'\n",
    "columns = tuple(['Raw_ID', 'Raw_path'])\n",
    "positions = len(columns)\n",
    "sql = f\"INSERT INTO {table} ({','.join([str(s) for s in list(columns)])}) VALUES ({str('%s, '*len(columns)).strip().strip(',')})\" #SQL command structure\n",
    "val = [(\"\", \"./missing_ID_2.txt\"),\n",
    "      (\"\", \"./missing_ID_3.txt\"),\n",
    "      (\"\", \"./missing_ID_4.txt\"),\n",
    "      (\"\", \"./missing_ID_5.txt\")]# Values corresponding to the rows of an instance\n",
    "cursor.executemany(sql, val) # Execute multiple lines \n",
    "\n",
    "connection.commit() # Commit the change to happen\n",
    "\n",
    "print(cursor.rowcount, \"record inserted.\")\n",
    "print(f'Last ID: {cursor.lastrowid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e6ea4-0e52-4789-bf70-1b3b7babd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'datasets'\n",
    "sql_request = f\"SELECT * FROM {table}\"\n",
    "cursor.execute(sql_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6538f-bb26-4ee9-992d-0cbb116442b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data = pd.DataFrame({'GEO_ID':data.name,\n",
    "                           'Platform_ID':data.metadata['platform_id'][0],\n",
    "                          'Expererimental_protocol':data.metadata['type'][0],\n",
    "                          'Description': data.metadata['summary'][0]}, index=[0])\n",
    "table = 'datasets'\n",
    "\n",
    "#data.to_sql(table, con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566002cc-9940-43ff-8ca7-d55c11f12d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
